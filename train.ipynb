{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Lung-Cancer-Classification-from-Histopathological-Images* ##\n",
    "\n",
    "-> *mohammad sarhangzadeh*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random \n",
    "import tqdm as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataloader, Dataset\n",
    "\n",
    "import configs\n",
    "from utils import plot_train_samples\n",
    "from dataset import LungCancerDataset\n",
    "from model import ResNet18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "status = torch.cuda.is_available()\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "full_dataset = LungCancerDataset(root_dir='dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_split = 0.7\n",
    "val_split = 0.2\n",
    "test_split = 0.1\n",
    "indices = np.arange(len(full_dataset))\n",
    "train_indices, temp_indices, train_labels, temp_labels = train_test_split(\n",
    "    indices, full_dataset.labels, stratify=full_dataset.labels, test_size=(1 - train_split)\n",
    ")\n",
    "\n",
    "val_indices, test_indices = train_test_split(\n",
    "    temp_indices, stratify=temp_labels, test_size=test_split / (test_split + val_split)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = Subset(LungCancerDataset(root_dir='dataset', transform=configs.train_transforms), train_indices)\n",
    "val_dataset = Subset(LungCancerDataset(root_dir='dataset', transform=configs.val_transforms), val_indices)\n",
    "test_dataset = Subset(LungCancerDataset(root_dir='dataset', transform=configs.test_transforms), test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=configs.BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=configs.BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=configs.BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Training samples: {len(train_indices)}\")\n",
    "print(f\"Validation samples: {len(val_indices)}\")\n",
    "print(f\"Test samples: {len(test_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plot_train_samples(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=configs.LEARNING_RATE)\n",
    "model = ResNet18(num_classes=configs.NUM_CLASSES, hidden_dim=configs.HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs=configs.EPOCHS, device=configs.DEVICE, save_path='best_model.pth'):\n",
    "    model = model.to(device)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    train_f1_scores = []\n",
    "    val_f1_scores = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() \n",
    "        train_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_train_labels = []\n",
    "        all_train_preds = []\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=f'Training Epoch {epoch + 1}/{num_epochs}', leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad() \n",
    "            outputs = model(images)  \n",
    "            loss = criterion(outputs, labels) \n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_train_labels.extend(labels.cpu().numpy())\n",
    "            all_train_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        train_f1 = f1_score(all_train_labels, all_train_preds, average='weighted')\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        train_f1_scores.append(train_f1)\n",
    "\n",
    "        model.eval() \n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        all_val_labels = []\n",
    "        all_val_preds = []\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            for images, labels in tqdm(val_loader, desc='Validating', leave=False):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)  \n",
    "                loss = criterion(outputs, labels) \n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "                \n",
    "                all_val_labels.extend(labels.cpu().numpy())\n",
    "                all_val_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        val_f1 = f1_score(all_val_labels, all_val_preds, average='weighted')\n",
    "\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_f1_scores.append(val_f1)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Train F1 Score: {train_f1:.2f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%, Val F1 Score: {val_f1:.2f}')\n",
    "\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f'Model saved to {save_path}')\n",
    "\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies, train_f1_scores, val_f1_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_and_validate(model, train_loader, val_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies, train_f1_scores, val_f1_scores, num_epochs=configs.EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = ResNet18() \n",
    "model.load_state_dict(torch.load('lung_cancer_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "evaluate_model(model, test_loader, criterion, device=configs.DEVICE)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
